{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Paper: Ocean mixing in a shelf seas driven by energetic nonlinear internal waves\n",
    "\n",
    "Prepared for Journal of Geophysical Research: Oceans \\\n",
    "Notebook author: Chris A Whiwtwell \\\n",
    "Contact: chris.a.whitwell@outlook.com \\\n",
    "Date: 27/01/2023\n",
    "\n",
    "This notebook contains the analysis to estime the diapycnal diffusivity, K, from the model described by Ivey et al. (2018) and using the method first described in Jones et al. (2020) for one site (Example here is for 200m deep mooring).\\\n",
    "All imported modules are pip installable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.tsa.stattools as ts\n",
    "from scipy import stats\n",
    "from scipy import signal\n",
    "import wmtsa.modwt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_fn(x,axis=0,thresh=15):\n",
    "    if np.count_nonzero(~np.isnan(x)) >= thresh:\n",
    "        return np.nanmean(x,axis=axis)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def geometric_mean_fn(x,axis=0,thresh=15):\n",
    "    if np.count_nonzero(~np.isnan(x)) >= thresh:\n",
    "        return 10**(np.nanmean(np.log10(x),axis=axis))\n",
    "    else:\n",
    "        return np.nan    \n",
    "\n",
    "## Used to do a runs test for stationarity\n",
    "def prep(x,axis=0):\n",
    "    return np.nanmean(np.square(x),axis=axis)\n",
    "\n",
    "def runs(x,axis=0):\n",
    "    x_m = np.nanmedian(x,axis=axis)\n",
    "    x_p = np.roll(x,1,axis=axis)\n",
    "    \n",
    "    runs =  np.nansum((x>=x_m[:,:,None])*(x_p<x_m[:,:,None]) + (x < x_m[:,:,None])*(x_p >= x_m[:,:,None]),axis=axis,dtype='int64')\n",
    "    n1 = np.nansum(x>= x_m[:,:,None],axis=axis,dtype='int64')\n",
    "    n2 = x.shape[axis[0]]-n1  \n",
    "    runs_exp = ((2*n1*n2)/(n1+n2))+1\n",
    "    stan_dev = np.sqrt((2*n1*n2*(2*n1*n2-n1-n2))/(((n1+n2)**2)*(n1+n2-1)))\n",
    "    z = (runs-runs_exp)/stan_dev \n",
    "    return abs(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_path =  r\"../Data/SBE37SM-RS232_03711063_2019_04_24.cnv\"\n",
    "SBE56_path = r\"../Data/RowleyShoals_Gridded_Mooring_T_20sec.nc\"\n",
    "ADCP_path =  r\"../Data/RowleyShoals2019_RDIADCPData_float64.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['time','depth','temperature','conductivity','density','C1','C2','C3']\n",
    "df_CTD =  pd.read_csv(ctd_path,names=names,skiprows=304,delim_whitespace=True)\n",
    "mask = np.argwhere(df_CTD['depth'].values > 180)\n",
    "slope, intercept, r, p, se = stats.linregress(df_CTD['temperature'].values[mask].flatten(), df_CTD['density'].values[mask].flatten())\n",
    "print(f' rho = {slope:0.3f} theta + {intercept:0.3f}\\n r =  {r} \\n p = {p} \\n SE = {se}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tslyce = slice('2019-03-07 00:00','2019-04-06 00:00')\n",
    "ds_T =  xr.open_dataset(SBE56_path,group='T200').sel(time=tslyce).sel(depth=slice(8,160))\n",
    "# paths\n",
    "ds_ADCP = xr.open_dataset(ADCP_path,group='T200_RDI_75kHz_LR_24613').sel(time=tslyce).sel(distance=slice(0,170))\n",
    "ds_ADCP = ds_ADCP.rename({'distance':'depth'})\n",
    "ds_ADCP = ds_ADCP[['u','v']].interpolate_na(dim='time',limit=1)\n",
    "ds_ADCP =  ds_ADCP.rolling(time=3,min_periods=1).mean()\n",
    "\n",
    "depths = ds_ADCP.depth.values\n",
    "depth_dim = len(ds_ADCP.depth.values)\n",
    "time_dim = len(ds_ADCP.time.values)\n",
    "\n",
    "## Estimate shear analytically from Chebyshev smoothed velocity data \n",
    "cheby_order_shear = 20\n",
    "S =  np.empty((depth_dim,time_dim))\n",
    "\n",
    "for t,time in enumerate(ds_ADCP.time.values):\n",
    "    subt = ds_ADCP.isel(time=t)\n",
    "    Efit = np.polynomial.chebyshev.Chebyshev.fit(subt.depth.values,subt['u'].values,cheby_order_shear).deriv(m=1)\n",
    "    Nfit = np.polynomial.chebyshev.Chebyshev.fit(subt.depth.values,subt['v'].values,cheby_order_shear).deriv(m=1)\n",
    "    S[:,t] = np.sqrt((Efit(depths)**2) + (Nfit(depths)**2))\n",
    "\n",
    "S_int = xr.DataArray(S,dims=['depth','time'],coords={'depth':ds_ADCP.depth.values,'time':ds_ADCP.time.values})\n",
    "\n",
    "ds_T['Sb'] =  S_int.interp_like(ds_T['Temperature'],method='linear')\n",
    "ds_T['Sb'] = ds_T['Sb'].interpolate_na(dim='depth',method='nearest',fill_value='extrapolate')\n",
    "\n",
    "ds_T.attrs['slope'] = slope\n",
    "ds_T.attrs['intercept'] = intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now do a wavelet transform on all SBE56 data\n",
    "T_wavelet_coeff = [] ## rotated\n",
    "T_smooth = []\n",
    "T_details = []\n",
    "\n",
    "for d,depth in enumerate(ds_T.depth.values):\n",
    "    print(f'Performing MODWT for {depth} thermistor, progress: {d*100/len(ds_T.depth.values)}')\n",
    "    thermistor =  ds_T['Temperature'].sel(depth=depth).values\n",
    "    ### T\n",
    "    w,v = wmtsa.modwt.modwt(thermistor,wtf='la16')\n",
    "    J0 = w.info['J0']\n",
    "    # Hard thresholding\n",
    "    sigma = 0.001\n",
    "    N = len(thermistor)\n",
    "    js = np.arange(1,J0+1)\n",
    "    thresh = np.ones_like(w)*np.sqrt(2*(sigma**2)*np.log(N)/(2**js))[:,None]\n",
    "    w[abs(w) < thresh] = 0\n",
    "    wr,vr = wmtsa.modwt.cir_shift(w,v,subtract_mean_VJ0t=True)\n",
    "    T_wavelet_coeff.append(np.asarray(wr))\n",
    "    T_smooth.append(np.asarray(wmtsa.modwt.imodwt_smooth(v)))\n",
    "    T_details.append(np.asarray(wmtsa.modwt.imodwt_details(w)))\n",
    "    print(f'Completed MODWT for {depth} thermistor')\n",
    "\n",
    "js = np.arange(1,J0+1)\n",
    "j_low = 20*(2**js) # 2**js if using SBE56s\n",
    "j_high = 20*(2**(js+1))# 2**(js+1) if using SBE56s\n",
    "\n",
    "ds_T['js'] =  xr.DataArray(js,dims=['js'],attrs={'long_name':'Decomposition level','indexing':'1 indexed'})\n",
    "ds_T['j_low'] =  xr.DataArray(j_low,dims=['js'],attrs={'long_name':'Lower bound of passband'})\n",
    "ds_T['j_high'] =  xr.DataArray(j_high,dims=['js'],attrs={'long_name':'Upper bound of passband'})\n",
    "\n",
    "ds_T['wj'] =  xr.DataArray(np.asarray(T_wavelet_coeff),dims=['depth','js','time'],attrs={'long_name':'Temperature Wavelet Coefficients'})\n",
    "ds_T['T_smooths'] =  xr.DataArray(np.asarray(T_smooth)[:,:len(ds_T.time.values)],dims=['depth','time'],attrs={'long_name':'Temperature Smooths'})\n",
    "ds_T['T_details'] =  xr.DataArray(np.asarray(T_details)[:,:,:len(ds_T.time.values)],dims=['depth','js','time'],attrs={'long_name':'Temperature Details'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean T at 1 min and longer scales\n",
    "T_tide =  ds_T['Temperature'].rolling(time=3).mean()\n",
    "dT_dz_tide =  np.abs(T_tide.differentiate('depth'))\n",
    "###\n",
    "rho_bkd =  slope*T_tide + intercept\n",
    "drhobkd_dz =  rho_bkd.differentiate('depth')\n",
    "\n",
    "### Calculate minimum buoyancy period\n",
    "ds_T['N'] =  (np.sqrt(-9.81*drhobkd_dz/rho_bkd)).where(dT_dz_tide>0.001)\n",
    "ds_T['bp'] =  2*np.pi/(60*ds_T['N'])\n",
    "ds_T['mbp'] = ds_T['bp'].rolling(time=int(30*3),center=True,min_periods=1).min()\n",
    "ds_T['mbp'] =  ds_T['mbp'].interpolate_na(dim='time',limit=120*3)\n",
    "\n",
    "### Estimate temperature variance from time scales shorter than min. buoy per\n",
    "ds_T['mask'] =  (ds_T['mbp'] > ds_T['j_high'])\n",
    "ds_T['Tvar'] =  (ds_T['wj']**2).where(ds_T['mask']).sum(dim='js')\n",
    "\n",
    "## Testing period\n",
    "ds_T['T_low'] = ds_T['Temperature'].rolling(time=15,min_periods=1).mean()\n",
    "\n",
    "## Calcualte background temperature gradient and corresponding value for N\n",
    "ts =  np.empty_like(ds_T['T_low'].values)\n",
    "dtsdz = np.empty_like(ds_T['T_low'].values)\n",
    "rho_bkd = np.empty_like(ds_T['T_low'].values)\n",
    "drhobkd_dz =  np.empty_like(ds_T['T_low'].values)\n",
    "cheby_order_Temp = 10\n",
    "for t,time in enumerate(ds_T['T_low'].time.values):\n",
    "    subt = ds_T['T_low'].isel(time=t)\n",
    "    Ts = subt.values[~np.isnan(subt.values)]\n",
    "    Rs = slope*Ts+intercept\n",
    "    \n",
    "    Ds = subt.depth.values[~np.isnan(subt.values)]\n",
    "    \n",
    "    t_fit = np.polynomial.chebyshev.Chebyshev.fit(Ds,Ts,cheby_order_Temp)\n",
    "    ts[:,t] = t_fit(subt.depth.values)\n",
    "    dtsdz[:,t] = t_fit.deriv(m=1)(subt.depth.values)\n",
    "    \n",
    "    r_fit = np.polynomial.chebyshev.Chebyshev.fit(Ds,Rs,cheby_order_Temp)\n",
    "    rho_bkd[:,t] = r_fit(subt.depth.values)\n",
    "    drhobkd_dz[:,t] = r_fit.deriv(m=1)(subt.depth.values)\n",
    "                                  \n",
    "rho_bkd = xr.DataArray(rho_bkd,dims=['depth','time'],coords={'depth':ds_T.depth.values,'time':ds_T.time.values})\n",
    "drhobkd_dz = rho_bkd.differentiate('depth')\n",
    "###\n",
    "Nb = (np.sqrt(-9.81*drhobkd_dz/rho_bkd))\n",
    "ds_T['Nb'] = Nb \n",
    "ds_T['dTbdz'] = xr.DataArray(np.abs(dtsdz),dims=['depth','time'],coords={'depth':ds_T.depth.values,'time':ds_T.time.values})\n",
    "\n",
    "### Shear\n",
    "\n",
    "## Calculate what is needed for model\n",
    "ds_T['Le'] = np.sqrt(ds_T['Tvar'])/ds_T['dTbdz']\n",
    "ds_T['K'] =  0.09*(ds_T['Le']**2)*ds_T['Sb']\n",
    "ds_T['Ri'] =  (ds_T['Nb']**2)/(ds_T['Sb']**2)\n",
    "ds_T['JQ'] =  1025*4000*ds_T['K']*ds_T['dTbdz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### stationarity testing\n",
    "dT = ds_T['Temperature'].diff(dim='time',n=1)\n",
    "ready = dT.coarsen(time=3,boundary='pad').reduce(prep)\n",
    "stat = ready.coarsen(time=10,boundary='pad').reduce(runs)\n",
    "ds_T['stat'] = stat.reindex_like(ds_T['Temperature'],method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no = 3\n",
    "mask = np.ones_like(ds_T['K'].values).astype('bool')\n",
    "## Coarsen data from 20 sec sampling rate to 1 minute and QAQC for stationarity, minimum shear and temperature gradient \n",
    "ds_fs_coarse = xr.Dataset()\n",
    "fn  =  geometric_mean_fn #mean_fn #\n",
    "ds_fs_coarse['Temperature'] = ds_T['Temperature'].coarsen(time=no,boundary='pad').reduce(mean_fn)\n",
    "\n",
    "mask *= (ds_T['dTbdz'] > 0.002)\n",
    "ds_fs_coarse['dTbdz'] =  ds_T['dTbdz'].where(mask).coarsen(time=no,boundary='pad').reduce(fn)\n",
    "ds_fs_coarse['Nb'] =  ds_T['Nb'].where(mask).coarsen(time=no,boundary='pad').reduce(fn)\n",
    "ds_fs_coarse['bp'] =  ds_T['bp'].where(mask).coarsen(time=no,boundary='pad').reduce(mean_fn)\n",
    "ds_fs_coarse['mbp'] =  ds_T['mbp'].where(mask).coarsen(time=no,boundary='pad').reduce(mean_fn)\n",
    "\n",
    "\n",
    "mask = np.ones_like(ds_T['K'].values).astype('bool')\n",
    "mask *= (ds_T['Sb'] > 0.004)\n",
    "ds_fs_coarse['Sb'] =  ds_T['Sb'].where(mask).coarsen(time=no,boundary='pad').reduce(fn)\n",
    "\n",
    "mask = np.ones_like(ds_T['K'].values).astype('bool')\n",
    "mask *= (ds_T['Sb'] > 0.004)\n",
    "mask *= (ds_T['dTbdz'] > 0.002)\n",
    "ds_fs_coarse['Ri'] =  ds_T['Ri'].where(mask).coarsen(time=no,boundary='pad').reduce(fn)\n",
    "\n",
    "mask *= (ds_T['K'] < 1)&(ds_T['K'] > 10**-7)\n",
    "mask *= (ds_T['stat'] < 3)\n",
    "ds_fs_coarse['Le'] =  ds_T['Le'].where(mask).coarsen(time=no,boundary='pad').reduce(fn)\n",
    "ds_fs_coarse['Tvar'] =  ds_T['Tvar'].where(mask).coarsen(time=no,boundary='pad').reduce(fn)\n",
    "ds_fs_coarse['K'] =  ds_T['K'].where(mask).coarsen(time=no,boundary='pad').reduce(fn) # mean_fn\n",
    "ds_fs_coarse['JQ'] =  ds_T['JQ'].where(mask).coarsen(time=no,boundary='pad').reduce(fn) # geometric_mean_fn\n",
    "\n",
    "ds_fs_coarse.to_netcdf(r'RS2019_T200_FS_20sec Shear' + str(cheby_order_shear)+' Temp'+str(cheby_order_Temp)+'.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
